[配置官网文档](https://prometheus.io/docs/prometheus/latest/configuration/configuration/)
# prometheus.yml结构
```yaml
global:
  # How frequently to scrape targets by default.
  [ scrape_interval: <duration> | default = 1m ]

  # How long until a scrape request times out.
  [ scrape_timeout: <duration> | default = 10s ]

  # How frequently to evaluate rules.
  [ evaluation_interval: <duration> | default = 1m ]

  # The labels to add to any time series or alerts when communicating with
  # external systems (federation, remote storage, Alertmanager).
  external_labels:
    [ <labelname>: <labelvalue> ... ]

  # File to which PromQL queries are logged.
  # Reloading the configuration will reopen the file.
  [ query_log_file: <string> ]

# Rule files specifies a list of globs. Rules and alerts are read from
# all matching files.
rule_files:
  [ - <filepath_glob> ... ]

# A list of scrape configurations.
scrape_configs:
  [ - <scrape_config> ... ]

# Alerting specifies settings related to the Alertmanager.
alerting:
  alert_relabel_configs:
    [ - <relabel_config> ... ]
  alertmanagers:
    [ - <alertmanager_config> ... ]

# Settings related to the remote write feature.
remote_write:
  [ - <remote_write> ... ]

# Settings related to the remote read feature.
remote_read:
  [ - <remote_read> ... ]

# Storage related settings that are runtime reloadable.
storage:
  [ tsdb: <tsdb> ]
  [ exemplars: <exemplars> ]

# Configures exporting traces.
tracing:
  [ <tracing_config> ]
```

# gloabl（全局配置）
* scrape_interval:抓取数据的时间间隔,默认1m，建议15s
* scrape_timeout:抓取超时时间，默认10s，建议15s
* evaluation_interval:评估计算时间，主要和报警搭配，prometheus在这个指定时间能对报警规则和数据进行一次计算，看是否需要触发报警
举例配置：
```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s
```

# scrape_configs（指标抓举配置）
```yaml
# The job name assigned to scraped metrics by default.
job_name: <job_name>

# How frequently to scrape targets from this job.
[ scrape_interval: <duration> | default = <global_config.scrape_interval> ]

# Per-scrape timeout when scraping this job.
[ scrape_timeout: <duration> | default = <global_config.scrape_timeout> ]

# The HTTP resource path on which to fetch metrics from targets.
[ metrics_path: <path> | default = /metrics ]

static_configs:
  [ - <static_config> ... ]

# List of target relabel configurations.
relabel_configs:
  [ - <relabel_config> ... ]

# List of metric relabel configurations.
metric_relabel_configs:
  [ - <relabel_config> ... ]
```

jobname: 抓取任务名称
static_configs:静态配置指标
static_configs.targets:静态抓取指标的ip地址，可以配多个
举例：如下配置了node_exporter和docker的抓取任务配置
```yaml
scrape_configs:
  - job_name: 'node_export'
    static_configs:
     - targets: ['192.168.157.128:9100','192.168.157.129:9100']
  - job_name: 'docker'
    static_configs: 
     - targets: ['192.168.157.128:8080']
```
如果想收集指定参数，而不是想exporter抓取全部参数可以假如params参数
```yaml
scrape_configs:
  - job_name: 'node_export'
    static_configs:
     - targets: ['192.168.157.128:9100','192.168.157.129:9100']
     params:
       collect[]:
          - cpu
          - meminfo
```
# rule_files（告警规则配置）